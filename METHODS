# METHODS ‚Äî Benchmarking Vision Transformers and Convolutional Neural Networks for Mineral Prospectivity Mapping Using Sentinel-2 Imagery

This document describes the complete methodological workflow used in the research titled:

**‚ÄúBenchmarking Vision Transformers and Convolutional Neural Networks for Porphyry Cu‚ÄìAu Prospectivity Mapping Using Sentinel-2 Imagery: The Reko Diq Case Study.‚Äù**

It covers all steps from data acquisition to preprocessing, feature extraction, model training, and final prospectivity mapping.

---

# 1. Study Area
- Location: **Reko Diq Porphyry Cu‚ÄìAu Deposit**, Chagai District, Balochistan, Pakistan  
- Geological significance: One of the world‚Äôs largest undeveloped Cu‚ÄìAu resources  
- Remote sensing relevance: Host rocks, alteration zones, and gossan signatures detectable via Sentinel-2 MSI multispectral features.

---

# 2. Data Acquisition
- Source: **USGS EarthExplorer**
- Dataset: **Sentinel-2 Level-2A multispectral imagery**
- Bands used:
  - 9 MSI bands: B2, B3, B4, B8 (10 m), B5, B6, B7, B8A, B12 (20 m)
- Acquisition filters:
  - Cloud cover < 5%
  - Seasonally stable imagery
  - Complete coverage of alteration zone geometry

---

# 3. Preprocessing Workflow

###  3.1 Atmospheric Correction
- "Image is already atmospherically corrected (Level-2A). Additional reflectance scaling applied."

###  3.2 Spatial Resolution Standardization
- Resampled 20 m bands to **10 m** using bilinear interpolation  
- Ensures uniform pixel size across all MSI channels

###  3.3 Clipping to Study Area
- Masked imagery using the Reko Diq AOI polygon  
- Exported as analysis-ready georeferenced mosaic

###  3.4 Dataset Tiling (Patch Extraction)
- The final labeled gossan raster and all feature stacks (MSI, band ratios, PCA, MNF) were tiled into fixed-size image patches for CNN training. The tiling process used the following workflow:

- Tile size: 64 √ó 64 pixels
- Overlap: 50% overlap in both x and y directions
- Input stacks tiled:
- MSI (core)
- MSI + Band Ratios
- MSI + PCA + MNF
- Combined stacks (total 8 different inputs)

#### Label raster: 3 classes
- 0 = None (Background)
- 1 = Weak gossan signal
- 2 = Strong gossan signal

#### Tile classification rules:
- A tile is labeled ‚Äústrong‚Äù if ‚â• 12% of its pixels belong to class 2
- A tile is labeled ‚Äúweak‚Äù if ‚â• 5% of its pixels belong to class 1
- Otherwise, the tile is labeled ‚Äúnone‚Äù
- All input rasters and the label raster were tiled in perfect alignment so each 64√ó64 tile had a matching label tile.

#### Train/validation/test split:
- 70% training
- 15% validation
- 15% testing

- Performed separately for each label class to maintain balance.
- Balanced dataset creation:
- Each class (none, weak, strong) was shuffled and split independently, resulting in balanced subsets for training, validation, and testing.

Complete preprocessing code:  
File: `Script/Preprocessing.py`

---

# 4. Feature Maps

One feature map was prepared:

---

## 4.1 MSI (Multispectral Bands Only)
- 9-band MSI stack  
- Captures raw spectral characteristics  
- Input shape: `64 √ó 64 √ó 9`

---

# 5. Model Architectures

Two pipelines were trained:

---

## 5.1 CNN Core (MSI only)
File: `Script/cnn_core.py`

- Input: 9 MSI bands  
- Architecture:
  - Conv2D ‚Üí ReLU ‚Üí MaxPool  
  - Conv2D ‚Üí ReLU ‚Üí MaxPool  
  - Dense ‚Üí Dropout  
  - Sigmoid/Softmax output  

---

## 5.2 ViT Core (MSI only)
File: `Script/vit_core.py`

- Input: 9 MSI bands  
- Architecture:
  - PatchExtractor ‚Üí PatchEmbedding
  - Transformer Encoder Block √ó 3
  - Multi-Head Self-Attention ‚Üí Add & Norm
  - Feed-Forward Dense (ReLU ‚Üí Dropout ‚Üí Dense ‚Üí Dropout) ‚Üí Add & Norm
  - LayerNormalization ‚Üí GlobalAveragePooling1D
  - Dense ‚Üí Dropout
  - Softmax output

---


# 6. Training Strategy

Both (CNN & ViT) architectures were trained in four configurations:

### 1) Scratch Model  
Random initialization, no augmentation.

### 2) Augmented Model  
Augmentations:
- Rotation  
- Horizontal/vertical flipping  
- Zoom    

### 3) Finetuned Head  
- Only dense layers of ResNet50 updated.
- Only dense layers of ViT_Base16 updated.

### 4) Fully Finetuned  
- Last three layers from CNN backbone of ResNet50 unfrozen and retrained.
- Last 3 encoder blocks + final LayerNorm of ViT_Base16 unfrozen and retrained

Validation accuracy curves:

- `results/figures/ViT_CNN_Scratch.jpg`
- `results/figures/ViT_CNN_Augmented.jpg`
- `results/figures/ViT_CNN_Finetuned_Head.jpg`
- `results/figures/ViT_CNN_Finetuned_Final.jpg`
- `results/figures/ViT_CNN_Validation_Comparison.jpg`

Comparison:  
`results/figures/paper_2_bar_graph.jpg`

---

All intermediate and final maps are available in:  
`results/maps/`

---

# 7. Reproducibility

This repository includes:

- Preprocessing code ‚Üí `Script/Preprocessing.py`  
- Feature stacks (generated by scripts)  
- Model scripts ‚Üí `/Script/`  
- All figures & maps ‚Üí `/results/`  
- Dependencies ‚Üí `requirements.txt`  
- Execution instructions ‚Üí `README.md`  
- Licensing ‚Üí MIT license

The workflow is **fully reproducible** using public Sentinel-2 data.

---

# üìò End of METHODS.md
